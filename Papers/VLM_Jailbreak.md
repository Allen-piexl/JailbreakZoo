# Timeline 🚀 
(Jan:❄️, Feb:💕, Mar:🌱, Apr:🌸, May:🌺, Jun:☀️, Jul:🍦, Aug:🌴, Sep:🍂, Oct:🎃, Nov:🦃, Dec:🎄)

[2024-02-13] 💕 Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast [[Paper](https://arxiv.org/abs/2402.08567.pdf)][[Code](https://sail-sg.github.io/Agent-Smith/)]

[2024-02-04] 💕 Jailbreaking Attack against Multimodal Large Language Model [[Paper](https://arxiv.org/abs/2402.02309.pdf)][[Code](https://github.com/abc03570128/Jailbreaking-Attack-against-Multimodal-Large-Language-Model)]

[2024-02-03] 💕 Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large Language Models [[Paper](https://arxiv.org/abs/2402.02207.pdf)][[Code](https://github.com/ys-zong/VLGuard)]

[2023-11-15] ❄️ Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts [[Paper](https://arxiv.org/abs/2311.09127.pdf)]
