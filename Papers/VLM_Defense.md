# Timeline ğŸš€ 
(Jan:â„ï¸, Feb:ğŸ’•, Mar:ğŸŒ±, Apr:ğŸŒ¸, May:ğŸŒº, Jun:â˜€ï¸, Jul:ğŸ¦, Aug:ğŸŒ´, Sep:ğŸ‚, Oct:ğŸƒ, Nov:ğŸ¦ƒ, Dec:ğŸ„)


[2024-05-26] ğŸŒº Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models VLM [[Paper](https://arxiv.org/pdf/2405.20775)][[Code](https://github.com/dirtycomputer/O2M_attack)]

[2024-05-25] ğŸŒº Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Characte VLM [[Paper](https://arxiv.org/pdf/2405.20773)]

[2024-04-08] ğŸŒ¸ Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in Multimodal Large Language Model Security [[Paper](https://arxiv.org/pdf/2404.05264.pdf)]

[2024-03-14] ğŸŒ± AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting [Paper](https://arxiv.org/pdf/2402.08567.pdf)][[Code](https://github.com/rain305f/AdaShield)]

[2024-02-03] ğŸ’• Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large Language Models [[Paper](https://arxiv.org/pdf/2402.02207.pdf)][[Code](https://github.com/ys-zong/VLGuard)]

[2023-12-17] ğŸ„ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection [[Paper](https://arxiv.org/pdf/2312.10766.pdf)][[Code](https://github.com/shiningrain/JailGuard)]

[2023-11-29] ğŸ¦ƒ MM-SafetyBench: A Benchmark for Safety Evaluation of Multimodal Large Language Models [[Paper](https://arxiv.org/pdf/2311.17600.pdf)]

